replicas: 2

# -- URL to the CAST AI API server.
apiURL: "api.cast.ai"

# -- Token to be used for authorizing access to the CAST AI API.
#
apiKey: ""

# apiKeySecretRef -- Name of secret with Token to be used for authorizing DBO access to the API
# apiKey and apiKeySecretRef are mutually exclusive
# The referenced secret must provide the token in .data["API_KEY"].
apiKeySecretRef: ""

# -- ID of the cache group for which cache configuration should be pulled.
#
cacheGroupID: ""

# protocol -- Specifies database protocol to be used for communication and query parsing.
protocol: "PostgreSQL"

service:
  # -- Traffic distribution policy for the service. Set to "PreferClose" to reduce inter-zone traffic.
  # Requires Kubernetes 1.31+.
  # Ref: https://kubernetes.io/docs/reference/networking/virtual-ips/#traffic-distribution
  trafficDistribution: ""

# commonLabels -- Labels to add to all resources.
commonLabels: {}

# commonAnnotations -- Annotations to add to all resources.
commonAnnotations: {}

# -- CAST.AI workload optimization annotations.
# Leave as null to apply default configuration with CPU minimums derived from resources.queryProcessor.cpu and resources.proxy.cpu.
# Set to {} (empty map) to disable workload annotations entirely.
# Set to custom values to override with your own annotations.
# Ref: https://docs.cast.ai/docs/workload-autoscaling
workloadsAnnotations: null
# To disable: workloadsAnnotations: {}
# Example custom configuration:
# workloadsAnnotations:
#   workloads.cast.ai/configuration: |
#     vertical:
#       memory:
#         optimization: on
#       cpu:
#         optimization: auto
#     containers:
#       query-processor:
#         cpu:
#           min: "4"
#           max: "8"
#       proxy:
#         cpu:
#           min: "1"
#           max: "2"

# -- Extra labels to add to the pod.
podLabels: {}

# -- Extra annotations to add to the pod.
podAnnotations: {}

resources:
  proxy:
    cpu: "500m"
    memoryRequest: "2Gi"
    memoryLimit: "2Gi"
  queryProcessor:
    cpu: "2"
    memoryRequest: "1Gi"
    memoryLimit: "1Gi"

# -- A list of upstream database endpoints
endpoints:
  -
    # -- Hostname of the upstream database instance.
    hostname: sample-db-hostname
    # -- Port for the endpoint on DBO pod.
    port: 5433
    # -- Port of the upstream database instance.
    targetPort: 5432
    # -- Name of the service. If this value is not empty, then additional cluster IP service will be deployed, using provided name as a suffix
    name:
    # -- Port of the named service
    servicePort: 5432
    # -- Envoy service discovery settings.
    # Ref: https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto.html
    serviceDiscovery:
      # -- The service discovery type to use for resolving the cluster. Available options: LOGICAL_DNS and STRICT_DNS.
      # Ref: https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/upstream/service_discovery
      type: LOGICAL_DNS
      dns_lookup_family: ALL
      respect_dns_ttl: true
      dns_refresh_rate: 5000ms

proxy:
  # -- Default proxy log level.
  logLevel: "filter:info"
  # -- Number of parallel processing streams. Use 0 to auto-calculate based on CPU limits.
  concurrency: 0
  # -- DNS lookup mode when communicating to outside. will prioritize IPV4 addresses. change to V6_ONLY to use v6 addresses instead.
  dnsLookupFamily: V4_PREFERRED
  # -- Defines "emptyDir.medium" value for data storage volume. Set to "Memory" for tmpfs disk
  dataStorageMedium: Memory
  # -- Predrain timeout in seconds.
  drainPreHook: 2
  # -- Default drain time in seconds.
  drainTimeSeconds: 60
  # -- Extra network debug logging.
  networkDebug: false
  # -- Name of a Kubernetes TLS Secret that contains the key pair to use for configuring TLS in the proxy. If not set, defaults to using a built-in key pair.
  tlsSecretName:
  # -- Envoy upstream connection limits, numbers given are the envoy defaults.
  connectionLimits:
    maxConnections: 10000          # Maximum number of connections per instance.
    maxPendingRequests: 1024       # Maximum requests queued while waiting for a connection
    maxRequests: 1024              # Maximum parallel requests per connection
    maxRetries: 3                  # Maximum parallel retries
  # -- Disable core dump collection by default
  coredumpCollectionMode: "None"
  # -- Cache configuration
  cache:
    # -- Maximum cache size in bytes, _should_ be divisible by cacheShards
    cacheSizeBytes: 2147483648    # 2 GiB
    # -- Number of cache shards _must_ be power of 2. Use 0 to auto-calculate based on concurrency.
    cacheShards: 0
    # -- Maximum size of in-flight cache entries, _should_ be divisible by pendingShards
    pendingSizeBytes: 134217728  # 128 MiB
    # -- Number of in-flight cache shards _must_ be power of 2.  Use 0 to auto-calculate based on concurrency.
    pendingShards: 0

queryProcessor:
  # -- Default query-processor log level.
  logLevel: "warn"
  # -- Default query-processor query cache item size.
  queryCacheSize: 100000
  # -- Default query-processor query cache byte size.
  queryCacheBytes: 524288000  # 500 MiB
  # -- Number of worker threads. This should ideally be tuned around 1.5 - 2x times more than expected amount of CPU usage.
  concurrency: 10
  # -- Enable additional debugging features to aid troubleshooting.
  debug: false

cloudSqlProxy:
  # -- Enable Cloud SQL Proxy sidecar
  enabled: false
  # -- Starting number from which unique ports are sequentially assigned to each upstream Cloud SQL instance
  basePort: 10000
  # -- Have the proxy connect over private IP if connecting from a VPC-native GKE cluster
  privateIp: false
  # -- Have the proxy connect with Automatic IAM authentication
  autoIamAuthn: false

pgdog:
  # -- Enable pgdog connection pooler sidecar
  enabled: false
  # -- Pgdog user (plain string). Mutually exclusive with usersSecretRef
  user: ""
  # -- Pgdog password (plain string). Mutually exclusive with usersSecretRef
  password: ""
  # -- Reference to existing secret containing users.toml file. Mutually exclusive with user/password
  # The secret must contain a key named "users.toml" with the pgdog users configuration
  usersSecretRef: ""
  resources:
    cpu: "500m"
    memory: "256Mi"
  # -- Pgdog general configuration settings. Corresponds to [general] section in pgdog.toml: https://docs.pgdog.dev/configuration/pgdog.toml/general/.
  config:
    # -- Count of Tokio threads spawned at startup; recommended setting is two per virtual CPU
    workers: 10
    # -- Default maximum number of server connections per database pool
    default_pool_size: 10
    # -- Default pooler mode to use for database pools. Options: "session", "transaction", "statement"
    pooler_mode: "transaction"
    # -- Enables prepared statement support with varying levels of rewriting capability. Options: "disabled", "extended", "extended_anonymous", "full"
    prepared_statements: "extended_anonymous"
    # -- Frequency of healthchecks performed by PgDog to ensure connections provided to clients from the pool are working (in milliseconds)
    healthcheck_interval: 30000
    # -- Frequency of healthchecks performed by PgDog on idle connections (in milliseconds)
    idle_healthcheck_interval: 30000
    # -- Delay running idle healthchecks at PgDog startup to give databases (and pools) time to spin up (in milliseconds)
    idle_healthcheck_delay: 5000
    # -- Health check timeout in milliseconds (custom field, not in official pgdog docs)
    healthcheck_timeout: 5000
    # -- How long to allow for ROLLBACK queries to run on server connections with unfinished transactions (in milliseconds)
    rollback_timeout: 5000
    # -- Maximum amount of time to allow for PgDog to create a connection to Postgres (in milliseconds)
    connect_timeout: 5000
    # -- Maximum amount of time a client is allowed to wait for a connection from the pool (in milliseconds)
    checkout_timeout: 10000
    # -- How long to wait for active clients to finish transactions when shutting down (in milliseconds)
    shutdown_timeout: 60000
    # -- Force-enable query parsing for advanced features like advisory locks in non-sharded databases
    query_parser_enabled: true
    # -- Path to the TLS certificate PgDog will use to setup TLS connections with clients
    tls_certificate: "/etc/ssl/certs/ssl-cert-snakeoil.pem"
    # -- Path to the TLS private key PgDog will use to setup TLS connections with clients
    tls_private_key: "/etc/ssl/private/ssl-cert-snakeoil.key"
    # -- Determines how TLS connections to Postgres servers are handled. Options: "none", "prefer", "verify_ca", "verify_full"
    tls_verify: "prefer"
    # -- If enabled, log every time a user creates a new connection to PgDog
    log_connections: false
    # -- If enabled, log every time a user disconnects from PgDog
    log_disconnections: false
    # -- Maximum number of prepared statements that can be cached per connection
    prepared_statements_limit: 5000
    # -- Maximum number of entries in the query cache
    query_cache_limit: 500
    # -- Enables/disable passthrough authentication. Option: "enabled_plain", "disabled". Although PgDog supports just "enabled", we do not as communication is container-container and using TLS would only add unnecessary overhead
    passthrough_auth: "disabled"

queryProcessorImage:
  repository: us-docker.pkg.dev/castai-hub/library/query-processor
  pullPolicy: IfNotPresent
  tag: ""  # uses values from _versions.tpl for default value

proxyImage:
  repository: us-docker.pkg.dev/castai-hub/library/dbo-proxy
  pullPolicy: IfNotPresent
  tag: ""  # uses values from _versions.tpl for default value

cloudSqlProxyImage:
  repository: gcr.io/cloud-sql-connectors/cloud-sql-proxy
  pullPolicy: IfNotPresent
  tag: ""  # uses values from _versions.tpl for default value

pgdogImage:
  repository: ghcr.io/pgdogdev/pgdog
  pullPolicy: IfNotPresent
  tag: ""  # uses values from _versions.tpl for default value

# -- The name of the service account to be used by the pod.
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
serviceAccountName: ""

# -- Pod toleration rules.
# Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: {}

# -- Pod node selector rules.
# Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
nodeSelector: {}

# -- Pod affinity rules.
# Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
affinity:
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
                # this will get replaced with actual app name
                - APP_NAME
        topologyKey: kubernetes.io/hostname

  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/os
              operator: NotIn
              values:
                - windows
            - key: kubernetes.io/arch
              operator: In
              values:
                - amd64
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
            - key: provisioner.cast.ai/managed-by
              operator: In
              values:
                - cast.ai

# -- Pod topology spread constraints.
# Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
topologySpreadConstraints: []

# -- Pod DNS policy.
# WARNING: If using dnsPolicy "None" with custom nameservers, ensure they can
# resolve cluster-internal DNS names (*.svc.cluster.local) for peer discovery
# to work correctly with the headless service.
# Ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy
dnsPolicy: ""

# -- Pod DNS configuration.
# Ref: https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config
dnsConfig: {}
