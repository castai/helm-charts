apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "vllm.fullname" . }}
  labels:
    model.aibrix.ai/port: {{ .Values.container.port | quote }}
    {{- include "vllm.labels" . | nindent 4 }}
    {{- with .Values.deployment.labels }}
    {{- toYaml . | nindent 4 }}
    {{- end }}
  annotations:
    workloads.cast.ai/configuration: |
      vertical:
        optimization: off
      horizontal:
        optimization: off
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "vllm.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "vllm.labels" . | nindent 8 }}
        {{- with .Values.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      volumes:
        {{- if .Values.tensorParallelSize }}
        # vLLM needs to access the host's shared memory for tensor parallel inference.
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: "10Gi"
        {{- end }}
        {{- if eq .Values.model.sourceRegistry "gcs" }}
        - name: gcs-credentials-model
          secret:
            secretName: {{ include "modelRegistrySecretName" . }}
            items:
              - key: gcsCredentialsJson
                path: credentials.json
        {{- end }}
        {{- if and .Values.loraAdapter.name (eq .Values.loraAdapter.sourceRegistry "gcs") }}
        - name: gcs-credentials-lora
          secret:
            secretName: {{ include "loraRegistrySecretName" . }}
            items:
              - key: gcsCredentialsJson
                path: credentials.json
        {{- end }}
        - name: models
          emptyDir: {}
      containers:
        - name: "vllm"
          image: "{{ required "Required value 'image.repository' must be defined" .Values.image.repository }}:{{ required "Required value 'image.tag' must be defined" .Values.image.tag }}"
          imagePullPolicy: IfNotPresent
          command: ["vllm", "serve"]
          args:
            - "--model={{ include "modelReference" . }}"
            - "--served-model-name={{ .Values.model.name }}"
            {{- if .Values.loraAdapter.name }}
            - "--enable-lora"
            - "--max-lora-rank={{ .Values.maxLoraRank }}"
            - "--lora-modules"
            - '{"name": "{{ .Values.loraAdapter.name }}", "path": "{{ include "loraAdapterPath" . }}", "base_model_name": "{{ .Values.model.name }}"}'
            {{- end }}
            {{- if .Values.useRunAiStreamer }}
            - "--load-format=runai_streamer"
            {{- end }}
            - "--trust-remote-code"
            {{- if .Values.gpuMemoryUtilization }}
            - "--gpu-memory-utilization={{ .Values.gpuMemoryUtilization }}"
            {{- end }}
            {{- if .Values.maxNumSeqs }}
            - "--max-num-seqs={{ .Values.maxNumSeqs }}"
            {{- end }}
            - "--task={{ required "Required value 'task' must be defined" .Values.task }}"
            - "--dtype={{ required "Required value 'dtype' must be defined" .Values.dtype }}"
            - "--kv-cache-dtype={{ required "Required value 'kvCacheDtype' must be defined" .Values.kvCacheDtype }}"
            {{- if .Values.enableChunkedPrefill }}
            - "--enable-chunked-prefill"
            {{- end }}
            {{- if .Values.maxNumBatchedTokens }}
            - "--max-num-batched-tokens={{ .Values.maxNumBatchedTokens }}"
            {{- end }}
            {{- if .Values.enableAutoToolChoice }}
            - "--enable-auto-tool-choice"
            {{- end }}
            {{- if .Values.toolCallParser }}
            - "--tool-call-parser={{ .Values.toolCallParser }}"
            {{- end }}
            {{- if .Values.reasoningParser }}
            - "--reasoning-parser={{ .Values.reasoningParser }}"
            {{- end }}
            - "--download-dir=/models"
            {{- if .Values.maxModelLen }}
            - "--max-model-len={{ .Values.maxModelLen }}"
            {{- end }}
            {{- if .Values.tensorParallelSize }}
            - "--tensor-parallel-size={{ .Values.tensorParallelSize }}"
            {{- end }}
            {{- if .Values.quantization }}
            - "--quantization={{ .Values.quantization }}"
            {{- end }}
            {{- if .Values.enableEager }}
            - "--enforce-eager"
            {{- end }}
            {{- if .Values.swapSpace }}
            - "--swap-space={{ .Values.swapSpace }}" # in GiB
            {{- end }}
            - "--show-hidden-metrics-for-version=0.10" # temp fix because AIBrix controller still uses the deprecated metrics
          env:
            - name: VLLM_IMAGE_FETCH_TIMEOUT # MM Models
              value: "60"
            - name: HF_HOME # Otherwise transformers will not respect download dir in vLLM
              value: /models
            - name: LD_LIBRARY_PATH
              value: "/usr/local/nvidia/lib:/usr/local/nvidia/lib64:${LD_LIBRARY_PATH}"
            {{- if eq .Values.model.sourceRegistry "gcs" }}
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: "/etc/gcs-credentials/credentials.json"
            {{- end }}
            {{- if eq .Values.model.sourceRegistry "s3" }}
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsAccessKeyId"
                  optional: true
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsSecretAccessKey"
                  optional: true
            - name: AWS_REGION
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsRegion"
                  optional: true
            - name: AWS_DEFAULT_REGION
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsRegion"
                  optional: true
            - name: AWS_ENDPOINT_URL
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsEndpointUrl"
                  optional: true
            {{- end }}
            {{- if or (eq .Values.model.sourceRegistry "hf") .Values.model.registry.hf.token }}
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "hfToken"
                  optional: true
            {{- end }}
            {{- if and .Values.loraAdapter.name (eq .Values.loraAdapter.sourceRegistry "hf") }}
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ include "loraRegistrySecretName" . }}
                  key: "hfToken"
                  optional: true
            {{- end }}
            {{- with .Values.env }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          ports:
            - name: http
              containerPort: {{ .Values.container.port }}
              protocol: TCP
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          {{- if .Values.startupProbe.enabled }}
          startupProbe:
            httpGet:
              path: {{ .Values.startupProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.startupProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.startupProbe.periodSeconds }}
            failureThreshold: {{ .Values.startupProbe.failureThreshold }}
            timeoutSeconds: {{ .Values.startupProbe.timeoutSeconds }}
            successThreshold: {{ .Values.startupProbe.successThreshold }}
          {{- end }}
          {{- if .Values.livenessProbe.enabled }}
          livenessProbe:
            httpGet:
              path: {{ .Values.livenessProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.livenessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.livenessProbe.periodSeconds }}
            failureThreshold: {{ .Values.livenessProbe.failureThreshold }}
            timeoutSeconds: {{ .Values.livenessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.livenessProbe.successThreshold }}
          {{- end }}
          {{- if .Values.readinessProbe.enabled }}
          readinessProbe:
            httpGet:
              path: {{ .Values.readinessProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.readinessProbe.periodSeconds }}
            failureThreshold: {{ .Values.readinessProbe.failureThreshold }}
            timeoutSeconds: {{ .Values.readinessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.readinessProbe.successThreshold }}
          {{- end }}
          volumeMounts:
          {{- if .Values.tensorParallelSize }}
            - name: shm
              mountPath: /dev/shm
          {{- end }}
            - name: models
              mountPath: /models
          {{- if eq .Values.model.sourceRegistry "gcs" }}
            - name: gcs-credentials-model
              mountPath: /etc/gcs-credentials
              readOnly: true
          {{- end }}
      initContainers:
        {{- if and (ne .Values.model.sourceRegistry "hf") (not .Values.useRunAiStreamer) }}
        - name: model-downloader-base
          image: "{{ .Values.modelDownloader.image.repository }}:{{ .Values.modelDownloader.image.tag }}"
          imagePullPolicy: IfNotPresent
          args:
            - download
          env:
            {{- include "modelDownloader.modelEnvVars" (list .Values.model.sourceRegistry .) | nindent 12 }}
            - name: MODEL_DOWNLOADER_REMOTE_SOURCE_DIRS
              value: "{{ .Values.model.name }}"
            - name: MODEL_DOWNLOADER_LOCAL_DESTINATION_DIR
              value: "/models"
          volumeMounts:
            - name: models
              mountPath: /models
            {{- if eq .Values.model.sourceRegistry "gcs" }}
            - name: gcs-credentials-model
              mountPath: /etc/gcs-credentials-model
              readOnly: true
            {{- end }}
          resources:
            {{- toYaml .Values.modelDownloader.resources | nindent 12 }}
        {{- end }}
        {{- if and .Values.loraAdapter.name (ne .Values.loraAdapter.sourceRegistry "hf") }}
        - name: model-downloader-lora
          image: "{{ .Values.modelDownloader.image.repository }}:{{ .Values.modelDownloader.image.tag }}"
          imagePullPolicy: IfNotPresent
          args:
            - download
          env:
            {{- include "modelDownloader.loraEnvVars" (list .Values.loraAdapter.sourceRegistry .) | nindent 12 }}
            - name: MODEL_DOWNLOADER_REMOTE_SOURCE_DIRS
              value: "{{ .Values.loraAdapter.name }}"
            - name: MODEL_DOWNLOADER_LOCAL_DESTINATION_DIR
              value: "/models"
          volumeMounts:
            - name: models
              mountPath: /models
            {{- if eq .Values.loraAdapter.sourceRegistry "gcs" }}
            - name: gcs-credentials-lora
              mountPath: /etc/gcs-credentials-lora
              readOnly: true
            {{- end }}
          resources:
            {{- toYaml .Values.modelDownloader.resources | nindent 12 }}
        {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
