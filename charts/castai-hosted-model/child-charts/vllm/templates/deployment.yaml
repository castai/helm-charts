apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "vllm.fullname" . }}
  labels:
    model.aibrix.ai/port: {{ .Values.container.port | quote }}
    {{- include "vllm.labels" . | nindent 4 }}
    {{- with .Values.deployment.labels }}
    {{- toYaml . | nindent 4 }}
    {{- end }}
  annotations:
    workloads.cast.ai/configuration: |
      vertical:
        optimization: off
      horizontal:
        optimization: off
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "vllm.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "vllm.labels" . | nindent 8 }}
        {{- with .Values.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      volumes:
        {{- if .Values.tensorParallelSize }}
        # vLLM needs to access the host's shared memory for tensor parallel inference.
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: "10Gi"
        {{- end }}
        {{- if eq .Values.model.sourceRegistry "gcs" }}
        - name: gcs-credentials-model
          secret:
            secretName: {{ include "modelRegistrySecretName" . }}
            items:
              - key: gcsCredentialsJson
                path: credentials.json
        {{- end }}
        {{- if and .Values.loraAdapter.name (eq .Values.loraAdapter.sourceRegistry "gcs") }}
        - name: gcs-credentials-lora
          secret:
            secretName: {{ include "loraRegistrySecretName" . }}
            items:
              - key: gcsCredentialsJson
                path: credentials.json
        {{- end }}
        - name: models
          emptyDir: {}
      containers:
        - name: "vllm"
          image: "{{ required "Required value 'image.repository' must be defined" .Values.image.repository }}:{{ required "Required value 'image.tag' must be defined" .Values.image.tag }}"
          imagePullPolicy: IfNotPresent
          command: ["vllm", "serve"]
          args:
            - "--model={{ include "modelReference" . }}"
            - "--served-model-name={{ .Values.model.name }}"
            {{- if .Values.loraAdapter.name }}
            - "--enable-lora"
            - "--max-lora-rank={{ .Values.maxLoraRank }}"
            - "--lora-modules"
            - '{"name": "{{ .Values.loraAdapter.name }}", "path": "/models/{{ .Values.loraAdapter.name }}", "base_model_name": "{{ .Values.model.name }}"}'
            {{- end }}
            {{- if .Values.useRunAiStreamer }}
            - "--load-format=runai_streamer"
            {{- end }}
            - "--trust-remote-code"
            {{- if .Values.gpuMemoryUtilization }}
            - "--gpu-memory-utilization={{ .Values.gpuMemoryUtilization }}"
            {{- end }}
            {{- if .Values.maxNumSeqs }}
            - "--max-num-seqs={{ .Values.maxNumSeqs }}"
            {{- end }}
            - "--task={{ required "Required value 'task' must be defined" .Values.task }}"
            - "--dtype={{ required "Required value 'dtype' must be defined" .Values.dtype }}"
            - "--kv-cache-dtype={{ required "Required value 'kvCacheDtype' must be defined" .Values.kvCacheDtype }}"
            {{- if .Values.enableChunkedPrefill }}
            - "--enable-chunked-prefill"
            {{- end }}
            {{- if .Values.maxNumBatchedTokens }}
            - "--max-num-batched-tokens={{ .Values.maxNumBatchedTokens }}"
            {{- end }}
            {{- if .Values.enableAutoToolChoice }}
            - "--enable-auto-tool-choice"
            {{- end }}
            {{- if .Values.toolCallParser }}
            - "--tool-call-parser={{ .Values.toolCallParser }}"
            {{- end }}
            {{- if .Values.reasoningParser }}
            - "--reasoning-parser={{ .Values.reasoningParser }}"
            {{- end }}
            - "--download-dir=/models"
            {{- if .Values.maxModelLen }}
            - "--max-model-len={{ .Values.maxModelLen }}"
            {{- end }}
            {{- if .Values.tensorParallelSize }}
            - "--tensor-parallel-size={{ .Values.tensorParallelSize }}"
            {{- end }}
            {{- if .Values.quantization }}
            - "--quantization={{ .Values.quantization }}"
            {{- end }}
            {{- if .Values.enableEager }}
            - "--enforce-eager"
            {{- end }}
            - "--show-hidden-metrics-for-version=0.10" # temp fix because AIBrix controller still uses the deprecated metrics
          env:
            - name: VLLM_IMAGE_FETCH_TIMEOUT # MM Models
              value: "60"
            - name: HF_HOME # Otherwise transformers will not respect download dir in vLLM
              value: /models
            - name: LD_LIBRARY_PATH
              value: "/usr/local/nvidia/lib:/usr/local/nvidia/lib64:${LD_LIBRARY_PATH}"
            {{- if eq .Values.model.sourceRegistry "gcs" }}
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: "/etc/gcs-credentials/credentials.json"
            {{- end }}
            {{- if eq .Values.model.sourceRegistry "s3" }}
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsAccessKeyId"
                  optional: true
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsSecretAccessKey"
                  optional: true
            - name: AWS_REGION
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsRegion"
                  optional: true
            - name: AWS_DEFAULT_REGION
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsRegion"
                  optional: true
            - name: AWS_ENDPOINT_URL
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "awsEndpointUrl"
                  optional: true
            {{- end }}
            {{- if or (eq .Values.model.sourceRegistry "hf") .Values.model.registry.hf.token }}
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ include "modelRegistrySecretName" . }}
                  key: "hfToken"
                  optional: true
            {{- end }}
            {{- with .Values.env }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          ports:
            - name: http
              containerPort: {{ .Values.container.port }}
              protocol: TCP
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          {{- if .Values.startupProbe.enabled }}
          startupProbe:
            httpGet:
              path: {{ .Values.startupProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.startupProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.startupProbe.periodSeconds }}
            failureThreshold: {{ .Values.startupProbe.failureThreshold }}
            timeoutSeconds: {{ .Values.startupProbe.timeoutSeconds }}
            successThreshold: {{ .Values.startupProbe.successThreshold }}
          {{- end }}
          {{- if .Values.livenessProbe.enabled }}
          livenessProbe:
            httpGet:
              path: {{ .Values.livenessProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.livenessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.livenessProbe.periodSeconds }}
            failureThreshold: {{ .Values.livenessProbe.failureThreshold }}
            timeoutSeconds: {{ .Values.livenessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.livenessProbe.successThreshold }}
          {{- end }}
          {{- if .Values.readinessProbe.enabled }}
          readinessProbe:
            httpGet:
              path: {{ .Values.readinessProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.readinessProbe.periodSeconds }}
            failureThreshold: {{ .Values.readinessProbe.failureThreshold }}
            timeoutSeconds: {{ .Values.readinessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.readinessProbe.successThreshold }}
          {{- end }}
          volumeMounts:
          {{- if .Values.tensorParallelSize }}
            - name: shm
              mountPath: /dev/shm
          {{- end }}
            - name: models
              mountPath: /models
          {{- if eq .Values.model.sourceRegistry "gcs" }}
            - name: gcs-credentials-model
              mountPath: /etc/gcs-credentials
              readOnly: true
          {{- end }}
      {{- if .Values.loraAdapter.name }}
      initContainers:
        {{- if eq .Values.loraAdapter.sourceRegistry "gcs" }}
        - name: lora-downloader-gcs
          image: "{{ .Values.modelDownloader.gcsImage }}"
          imagePullPolicy: IfNotPresent
          command: ["bash", "-c"]
          args:
            - |
              set -euo pipefail
              mkdir -p "/models/{{ .Values.loraAdapter.name }}" \
                && gsutil -m cp -r "gs://{{ .Values.loraAdapter.name }}/*" "/models/{{ .Values.loraAdapter.name }}/"
          env:
            - name: GOOGLE_APPLICATION_CREDENTIALS
              value: "/etc/gcs-credentials/credentials.json"
          volumeMounts:
            - name: models
              mountPath: /models
            - name: gcs-credentials-lora
              mountPath: /etc/gcs-credentials
              readOnly: true
          resources:
            {{- toYaml .Values.modelDownloader.resources | nindent 12 }}
        {{- else if eq .Values.loraAdapter.sourceRegistry "s3" }}
        - name: lora-downloader-s3
          image: "{{ .Values.modelDownloader.s3Image }}"
          imagePullPolicy: IfNotPresent
          command: ["bash", "-c"]
          args:
            - |
              set -euo pipefail
              mkdir -p "/models/{{ .Values.loraAdapter.name }}" \
                && aws s3 cp --recursive "s3://{{ .Values.loraAdapter.name }}/" "/models/{{ .Values.loraAdapter.name }}/"
          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: {{ include "loraRegistrySecretName" . }}
                  key: "awsAccessKeyId"
                  optional: true
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ include "loraRegistrySecretName" . }}
                  key: "awsSecretAccessKey"
                  optional: true
            - name: AWS_REGION
              valueFrom:
                secretKeyRef:
                  name: {{ include "loraRegistrySecretName" . }}
                  key: "awsRegion"
                  optional: true
            - name: AWS_DEFAULT_REGION
              valueFrom:
                secretKeyRef:
                  name: {{ include "loraRegistrySecretName" . }}
                  key: "awsRegion"
                  optional: true
            - name: AWS_ENDPOINT_URL
              valueFrom:
                secretKeyRef:
                  name: {{ include "loraRegistrySecretName" . }}
                  key: "awsEndpointUrl"
                  optional: true
          volumeMounts:
            - name: models
              mountPath: /models
          resources:
            {{- toYaml .Values.modelDownloader.resources | nindent 12 }}
        {{- else if eq .Values.loraAdapter.sourceRegistry "hf" }}
        - name: lora-downloader-hf
          image: "{{ .Values.modelDownloader.hfImage }}"
          imagePullPolicy: IfNotPresent
          command: ["bash", "-c"]
          args:
            - |
              set -euo pipefail
              pip install --no-cache-dir "huggingface_hub>=0.24.0"
              python - << "PY"
              import os
              from huggingface_hub import snapshot_download
              repo_id = "{{ .Values.loraAdapter.name }}"
              local_dir = "/models/{{ .Values.loraAdapter.name }}"
              token = os.environ.get("HUGGING_FACE_HUB_TOKEN") or None
              snapshot_download(repo_id=repo_id, local_dir=local_dir, token=token)
              PY
          env:
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ include "loraRegistrySecretName" . }}
                  key: "hfToken"
                  optional: true
          volumeMounts:
            - name: models
              mountPath: /models
          resources:
            {{- toYaml .Values.modelDownloader.resources | nindent 12 }}
        {{- end }}
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
