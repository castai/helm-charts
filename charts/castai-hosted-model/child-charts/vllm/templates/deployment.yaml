apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "vllm.fullname" . }}
  labels:
    model.aibrix.ai/port: {{ .Values.container.port | quote }}
    {{- include "vllm.labels" . | nindent 4 }}
    {{- with .Values.deployment.labels }}
    {{- toYaml . | nindent 4 }}
    {{- end }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "vllm.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "vllm.labels" . | nindent 8 }}
        {{- with .Values.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      volumes:
        {{ if .Values.tensorParallelSize }}
        # vLLM needs to access the host's shared memory for tensor parallel inference.
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: "10Gi"
        {{ end }}
        {{ if .Values.mountImageCache }}
        - name: llm-cache
          hostPath:
            path: /cache
            type: Directory
        {{ end }}
        {{ if include "requiresRegistry" (list "gcs" .) }}
        - name: gcs-credentials
          secret:
            secretName: {{ include "registrySecretName" . }}
            items:
              - key: gcsCredentialsJson
                path: credentials.json
        {{- end }}
        - name: models
          emptyDir: {}
      containers:
        - name: "vllm"
          image: "{{ required "Required value 'image.repository' must be defined" .Values.image.repository }}:{{ required "Required value 'image.tag' must be defined" .Values.image.tag }}"
          imagePullPolicy: IfNotPresent
          command: ["vllm", "serve"]
          args:
            - "--model={{ include "modelReference" . }}"
            - "--served-model-name={{ .Values.model.name }}"
            {{- if .Values.loraAdapter.name }}
            - "--enable-lora"
            - "--max-lora-rank={{ .Values.maxLoraRank }}"
            - "--lora-modules"
            - '{"name": "{{ .Values.loraAdapter.name }}", "path": "/models/{{ .Values.loraAdapter.name }}", "base_model_name": "{{ .Values.model.name }}"}'
            {{ end }}
            - "--load-format=runai_streamer"
            - "--trust-remote-code"
            {{ if .Values.gpuMemoryUtilization }}
            - "--gpu-memory-utilization={{ .Values.gpuMemoryUtilization }}"
            {{ end }}
            - "--task={{ required "Required value 'task' must be defined" .Values.task }}"
            - "--dtype={{ required "Required value 'dtype' must be defined" .Values.dtype }}"
            - "--kv-cache-dtype={{ required "Required value 'kvCacheDtype' must be defined" .Values.kvCacheDtype }}"
            {{ if .Values.enableChunkedPrefill }}
            - "--enable-chunked-prefill"
            {{ end }}
            {{ if .Values.maxNumBatchedTokens }}
            - "--max-num-batched-tokens={{ .Values.maxNumBatchedTokens }}"
            {{ end }}
            {{ if .Values.enableAutoToolChoice }}
            - "--enable-auto-tool-choice"
            {{ end }}
            {{ if .Values.toolCallParser }}
            - "--tool-call-parser={{ .Values.toolCallParser }}"
            {{ end }}
            - "--download-dir=/cache"
            {{ if .Values.maxModelLen }}
            - "--max-model-len={{ .Values.maxModelLen }}"
            {{ end }}
            {{ if .Values.tensorParallelSize }}
            - "--tensor-parallel-size={{ .Values.tensorParallelSize }}"
            {{ end }}
            {{ if .Values.quantization }}
            - "--quantization={{ .Values.quantization }}"
            {{ end }}
          env:
            - name: LD_LIBRARY_PATH
              value: "/usr/local/nvidia/lib:/usr/local/nvidia/lib64:${LD_LIBRARY_PATH}"
            - name: AWS_REQUEST_CHECKSUM_CALCULATION
              value: "when_required"
            - name: AWS_RESPONSE_CHECKSUM_VALIDATION
              value: "when_required"
            - name: AWS_ENDPOINT_URL
              value: "http://localhost:8080"
            - name: AWS_ACCESS_KEY_ID
              value: "local-identity"
            - name: AWS_SECRET_ACCESS_KEY
              value: "local-credential"
            - name: HUGGING_FACE_HUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: {{ include "registrySecretName" . }}
                  key: "hfToken"
                  optional: true
          ports:
            - name: http
              containerPort: {{ .Values.container.port }}
              protocol: TCP
          resources:
            {{ toYaml .Values.resources | nindent 12 }}
          startupProbe:
            httpGet:
              path: {{ .Values.startupProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.startupProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.startupProbe.periodSeconds }}
            failureThreshold: {{ .Values.startupProbe.failureThreshold }}
          livenessProbe:
            httpGet:
              path: {{ .Values.livenessProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.livenessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.livenessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.livenessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.livenessProbe.successThreshold }}
            failureThreshold: {{ .Values.livenessProbe.failureThreshold }}
          readinessProbe:
            httpGet:
              path: {{ .Values.readinessProbe.httpGet.path }}
              port: http
            initialDelaySeconds: {{ .Values.readinessProbe.initialDelaySeconds }}
            periodSeconds: {{ .Values.readinessProbe.periodSeconds }}
            timeoutSeconds: {{ .Values.readinessProbe.timeoutSeconds }}
            successThreshold: {{ .Values.readinessProbe.successThreshold }}
            failureThreshold: {{ .Values.readinessProbe.failureThreshold }}
          volumeMounts:
          {{ if .Values.tensorParallelSize }}
            - name: shm
              mountPath: /dev/shm
          {{ end }}
          {{ if .Values.mountImageCache }}
            - name: llm-cache
              mountPath: /cache
          {{ end }}
            - name: models
              mountPath: /models
      initContainers:
{{- if .Values.loraAdapter.name }}
        - name: model-downloader
          image: "{{ .Values.modelDownloader.image.repository }}:{{ .Values.modelDownloader.image.tag }}"
          imagePullPolicy: IfNotPresent
          args:
            - download
          env:
            - name: STORAGE_TYPE
              value: "gcs"
            - name: GCS_CREDENTIALS_FILE
              value: "/etc/gcs-credentials/credentials.json"
            - name: MODEL_DOWNLOADER_REMOTE_SOURCE_DIR
              value: "{{ .Values.loraAdapter.name }}"
            - name: MODEL_DOWNLOADER_LOCAL_DESTINATION_DIR
              value: "/models/{{ .Values.loraAdapter.name }}"
          volumeMounts:
            - name: models
              mountPath: /models
            - name: gcs-credentials
              mountPath: /etc/gcs-credentials
              readOnly: true
          resources:
            {{ toYaml .Values.modelDownloader.resources | nindent 12 }}
{{- end }}
{{- if ne .Values.model.sourceRegistry "hf" }}
        - name: s3proxy
          image: "{{ .Values.modelDownloader.image.repository }}:{{ .Values.modelDownloader.image.tag }}"
          restartPolicy: Always
          imagePullPolicy: IfNotPresent
          args:
            - s3proxy
          ports:
            - name: s3proxy
              containerPort: 8080
              protocol: TCP
          env:
            - name: STORAGE_TYPE
              value: "gcs"
            - name: GCS_CREDENTIALS_FILE
              value: "/etc/gcs-credentials/credentials.json"
          volumeMounts:
            - name: gcs-credentials
              mountPath: /etc/gcs-credentials
              readOnly: true
          resources:
            {{ toYaml .Values.modelDownloader.s3ProxyResources | nindent 12 }}
{{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
