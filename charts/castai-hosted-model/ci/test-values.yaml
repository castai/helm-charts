vllm:
  replicaCount: 1
  service:
    name: vllm-test
    port: 11434
    type: ClusterIP
  image:
    # for now, vllm cpu images are kept only in AWS ECR
    # source: https://docs.vllm.ai/en/stable/getting_started/installation/cpu.html#pre-built-images
    repository: "public.ecr.aws/q9t5s3a7/vllm-cpu-release-repo"
    tag: "v0.9.2"

  dtype: "auto"
  model:
    name: "dummy/model"
    sourceRegistry: "hf"
  env:
    - name: HF_HUB_DISABLE_PROGRESS_BARS
      value: "1"
    - name: HF_HUB_DISABLE_TELEMETRY
      value: "1"
    - name: VLLM_DO_NOT_TRACK
      value: "1"
    # Environment variables that will cause vllm to fail fast without downloading
    - name: HF_HUB_OFFLINE
      value: "1"
    - name: HF_DATASETS_OFFLINE
      value: "1"
    - name: TRANSFORMERS_OFFLINE
      value: "1"

  # Minimal resource requirements for testing
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "512Mi"

  # Disable probes since the service will fail to start (expected)
  startupProbe:
    enabled: false
  livenessProbe:
    enabled: false
  readinessProbe:
    enabled: false
